{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b890b2-9b83-4f66-b777-df8fd83a521d",
   "metadata": {},
   "source": [
    "# Displaying a basic map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12079135-e927-4678-b07e-e23fa4f8ec15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "m = folium.Map([40.151449, -82.595882], zoom_start=8)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[39.967248, -83.006980],\n",
    "    tooltip=\"Click me!\",\n",
    "    popup=\"Michael Baker Intl. - Columbus\",\n",
    "    icon=folium.Icon(icon=\"cloud\"),\n",
    ").add_to(m)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[41.503252, -81.686686],\n",
    "    tooltip=\"Click me!\",\n",
    "    popup=\"Michael Baker Intl. - Cleveland\",\n",
    "    icon=folium.Icon(color=\"green\"),\n",
    ").add_to(m)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.799164, -81.376457],\n",
    "    tooltip=\"Click me!\",\n",
    "    popup=\"Michael Baker Intl. - Canton\",\n",
    "    icon=folium.Icon(color=\"green\"),\n",
    ").add_to(m)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[39.112037, -84.515471],\n",
    "    tooltip=\"Click me!\",\n",
    "    popup=\"Michael Baker Intl. - Cincinnati\",\n",
    "    icon=folium.Icon(color=\"green\"),\n",
    ").add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99541ea-89aa-49e6-a0c0-0f88d1cbae39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lines that start with `#` are comments, they don't execute code, these next lines import the necessary libraries to process the data\n",
    "import os\n",
    "import re\n",
    "import folium\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import earthpy as et\n",
    "import geopandas as gpd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea7bc96-618b-484c-baf7-6046833f5a95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a map using the City of Columbus's GPS Coordinates\n",
    "map_osm = folium.Map(location=[39.983334, -82.983330], zoom_start=11)\n",
    "map_osm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505be831-4a71-4c1b-8409-f9e4b17b496c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Building out a map from datapoints\n",
    "\n",
    "List of relevant Bridges to D6 - Within \"D6 Bridge Records project (ODOT internal)\": `Bridge_Record_CSVs_(Tracked_Changes)/BridgeListFromAssetWise.xlsx`\n",
    "\n",
    "Excel file is every bridge in Assetwise assigned to D6, filtered in assetwise and then exported as an excel file.\n",
    "\n",
    "Loading file via python (change the path in the next cell to use your own data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc561c5-d4d9-468b-a66d-57dec34fde93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assetwise_export_path = Path(\n",
    "    r\"C:\\Users\\dane.parks\\OneDrive - Michael Baker International\\Desktop\\python\\report.xlsx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16eb37f-53e1-4d7c-bb38-b9fa78c64d59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wb = openpyxl.load_workbook(assetwise_export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8111a5-eb0b-4be6-a72d-f5edc4b9edc8",
   "metadata": {},
   "source": [
    "make sure the correct file was found and that the hyperlinks are working/available by printing out first hyperlink:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b544bbb-ca1f-4f3a-bf33-03ed3a7cf129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ws = wb[\"Sheet1\"]\n",
    "print(ws.cell(row=2, column=1).hyperlink.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d983dd7-f4ba-494f-b1d6-00ddebbd0074",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using Pandas to access and filter raw data\n",
    "\n",
    "openpyxl is good for accessing aspects of excel's interface, like reading hyperlinks, but to filter/modify data, it needs to be loaded into pandas\n",
    "\n",
    "filter bridges by state maintenance (Column H - NBI 21 = 01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353beaf7-a29c-4b07-805e-9157fc520a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the data into memory\n",
    "all_bridges_df = pd.read_excel(assetwise_export_path)\n",
    "\n",
    "# Filter the data\n",
    "d6_bridges = all_bridges_df.loc[\n",
    "    all_bridges_df[\"NBI 021: Maintenance Responsibility(Report)\"] == 1.0\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f7a62-69e6-4970-bf05-91a4f5082749",
   "metadata": {},
   "source": [
    "Make sure the only values left in the table are one's ODOT Maintains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d54b998-4318-471e-b71d-27f6735cff76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Displays all unique values contained in the specified column of the dataframe\n",
    "d6_bridges[\"NBI 021: Maintenance Responsibility(Report)\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe95cd-9f8b-4fec-9c0a-f9e945e55516",
   "metadata": {},
   "source": [
    "## Getting SFN from larger string\n",
    "\n",
    "The format assetwise uses to hold the bridge name is regular, but not simple. Although Regex isn't necessarily required for this bit, as the built in split function for strings would work, it's powerful and understanding it is helpful.\n",
    "\n",
    "The goal is to get all the characters between the `(` and `)` from the following value. [This website](https://regex101.com/) is useful for testing the patterns, in this case, the pattern used is `'\\((.*?)\\)'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25bda1-0176-4194-a218-45ccc67a3b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the text that will be searched in the next cell\n",
    "d6_bridges.iloc[0][\"Asset Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36338d52-d8c6-4ca4-a8f4-7b5665bc9ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use a regular expression to extract the necessary value from the data and print it\n",
    "bridge_sfn = re.search(r\"\\((.*?)\\)\", d6_bridges.iloc[0][\"Asset Name\"]).group(1)\n",
    "bridge_sfn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753a77b-ce5b-4ac0-a7d9-7fd4afa92ef8",
   "metadata": {},
   "source": [
    "Now that we have the bridge's SFN, we can use the existing Civilpy tools to get a map for the structure, and various attributes from TIMs for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e64415f-acdd-40ef-9a5d-365e43f3dc19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the library I wrote/published\n",
    "from civilpy.state.ohio.DOT.legacy import TimsBridge\n",
    "\n",
    "# Lookup bridge values by sfn - '7700555'\n",
    "bridge_lookup_result = TimsBridge(\"7700555\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35325d50-1e75-4c32-bf86-78a3adeab0ca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "bridge_lookup_result.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c540ca-cc2a-44b7-a795-f2c28dd643d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"District: {bridge_lookup_result.district}\")\n",
    "print(f\"Structure: {bridge_lookup_result.SFN}\")\n",
    "print(\n",
    "    f\"{bridge_lookup_result.str_loc_carried} in \"\n",
    "    f\"{bridge_lookup_result.county_cd} County \"\n",
    "    f\"{bridge_lookup_result.invent_feat}\\n\"\n",
    ")\n",
    "\n",
    "print(f\"Latitude: {bridge_lookup_result.latitude_dd}\")\n",
    "print(f\"Longitude: {bridge_lookup_result.longitude_dd}\\n\")\n",
    "\n",
    "print(f\"Structure Material Code: {bridge_lookup_result.main_str_mtl_cd}\")\n",
    "print(f\"Structure Type Code: {bridge_lookup_result.main_str_type_cd}\\n\")\n",
    "\n",
    "print(f\"Number of Spans: {bridge_lookup_result.main_spans}\")\n",
    "print(f\"Number of Lanes On Structure: {bridge_lookup_result.lanes_on}\")\n",
    "\n",
    "print(f\"Number of Spans: {bridge_lookup_result.max_span_len}\")\n",
    "\n",
    "if bridge_lookup_result.main_spans == 3:\n",
    "    print(\n",
    "        f\"first and last span length: {(bridge_lookup_result.ovrl_str_len - bridge_lookup_result.max_span_len)/2}\\n\"\n",
    "    )\n",
    "\n",
    "print(f\"Bridge Roadway Width: {bridge_lookup_result.brg_rdw_wd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ca489-1bc5-4512-bc61-85bb14b08e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bridge_lookup_result.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2746828-a244-41ef-957f-0424439b5440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bridge_2100967 = TimsBridge(2100967)\n",
    "bridge_2100932 = TimsBridge(2100932)\n",
    "bridge_2100908 = TimsBridge(2100908)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c8b8a0-3821-4270-99be-097b682c095f",
   "metadata": {},
   "source": [
    "## Connecting to a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe52354-b5d0-4942-80c9-1cf7bc302733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../secrets.json\") as f:\n",
    "    secrets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc01234-13b7-4150-a108-3a1cc9cae672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import SSHTunnelForwarder\n",
    "from sqlalchemy.orm import sessionmaker  # Run pip install sqlalchemy\n",
    "from sqlalchemy import create_engine, text, desc\n",
    "\n",
    "server = SSHTunnelForwarder(\n",
    "    (\"daneparks.com\", 2271),  # Remote server IP and SSH port\n",
    "    ssh_username=secrets[\"SSH_USERNAME\"],\n",
    "    ssh_password=secrets[\"SSH_PASSWORD\"],\n",
    "    remote_bind_address=(\"localhost\", 5432),\n",
    ")\n",
    "\n",
    "server.start()  # start ssh sever\n",
    "print(\"Server connected via SSH\")\n",
    "\n",
    "# connect to PostgreSQL\n",
    "local_port = str(server.local_bind_port)\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{secrets['POSTGRES_USERNAME']}:{secrets['POSTGRES_PASSWORD']}@localhost:{local_port}/civilpy\"\n",
    ")\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "print(\"Database session created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108db1f2-3057-4449-b8a7-e961f6da69dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test data retrieval\n",
    "test = session.execute(\n",
    "    text(\"\"\" SELECT * FROM steel_members ORDER BY \"AISC_Manual_Label\" DESC \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bfb288-98e1-427b-ac7f-bc3fa535221a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "m = folium.Map([40.151449, -82.595882], zoom_start=8)\n",
    "\n",
    "iframe = folium.IFrame(\n",
    "    f\"Michael Baker Intl. - Columbus<br><br>The first Steel Shape in the DB is a:<br>{test.first()[3]}\"\n",
    ")\n",
    "variable_popup = folium.Popup(iframe, min_width=300, max_width=300)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[39.967248, -83.006980],\n",
    "    tooltip=\"Click me!\",\n",
    "    popup=variable_popup,\n",
    "    icon=folium.Icon(icon=\"cloud\"),\n",
    ").add_to(m)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[41.503252, -81.686686],\n",
    "    tooltip=\"Click me!\",\n",
    "    popup=\"Michael Baker Intl. - Cleveland\",\n",
    "    icon=folium.Icon(color=\"green\"),\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58de5b0-0006-4698-ab56-ce6c9674e8b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9763a794-8d67-469c-a360-b59661a928ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0287da45-e1db-48d9-a3e3-62a773717921",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5130fd-4f6b-4b4c-9acb-e2787c14ef67",
   "metadata": {},
   "source": [
    "## Use lookup values to build a map in KML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7a890-6d96-476b-aad4-2761ff38234a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = [bridge_2100967, bridge_2100932, bridge_2100908]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60618032-5d1c-4a9b-a43d-9aea401e37be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplekml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9482708-d063-4e02-8998-b206cd45b55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kml = simplekml.Kml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d7b56-c9a1-4fae-b1cc-a445d5b27047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    text_1 = f\"<H1>SFN:{a[i].SFN}</H1><br><br><p>latitude={a[i].latitude}<br>longitude={a[i].longitude}</p>\"\n",
    "    text_2 = f\"<br>original PID: {a[i].orig_proj_nbr}<br>BIA Report: {a[i].bia_report}<br>Photos: {a[i].photo_url}<br>StRtBrPhotos: {a[i].state_route_br_photos}\"\n",
    "    embed_text = text_1 + text_2\n",
    "\n",
    "    kml.newpoint(\n",
    "        name=a[i].SFN, coords=[(a[i].longitude, a[i].latitude)]\n",
    "    ).balloonstyle.text = embed_text\n",
    "\n",
    "kml.save(\"bridges.kml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b7cfea-c6d6-4ef4-bbd8-9acf700ce965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html \"Mapping Tools.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63451d-0819-41c0-a5da-622ae8f5ce62",
   "metadata": {},
   "source": [
    "# Convert KML to Folium Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb8a768c-1c3e-412f-a349-28e325f727ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import folium\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e20784f-5cfd-4256-aea2-c8d3f808524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_parent_folder(placemark):\n",
    "    # Walk up the tree to find the immediate <Folder>\n",
    "    parent = placemark.getparent()  # Get parent element\n",
    "    while parent is not None:  # Continue until the root\n",
    "        if parent.tag == f\"{{{namespace['kml']}}}Folder\":  # Check if it's a <Folder>\n",
    "            folder_name = parent.find('kml:name', namespace)\n",
    "            return folder_name.text if folder_name is not None else \"No Folder\"  # Get folder name\n",
    "        parent = parent.getparent()  # Continue up the tree\n",
    "    return \"No Folder\"  # If no folder is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d17ab3-ce14-4d89-ba3e-7c7c983c05b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bnsf_map(kmz_file_path):\n",
    "    # Step 1: Extract KMZ file\n",
    "    with zipfile.ZipFile(kmz_file_path, 'r') as kmz:\n",
    "        # Extract the KML file within the KMZ archive\n",
    "        kml_file_path = [name for name in kmz.namelist() if name.endswith('.kml')][0]\n",
    "        kml_content = kmz.read(kml_file_path)\n",
    "\n",
    "    # Step 2: Parse the KML file\n",
    "    namespace = {\"kml\": \"http://www.opengis.net/kml/2.2\"}\n",
    "    kml_root = ET.fromstring(kml_content)\n",
    "    document = kml_root.find('kml:Document', namespace)\n",
    "\n",
    "    placemarks = document.findall(\".//kml:Placemark\", namespace)\n",
    "\n",
    "    data = []\n",
    "    for placemark in placemarks:\n",
    "        name = placemark.find('kml:name', namespace).text if placemark.find('kml:name',\n",
    "                                                                            namespace) is not None else 'No Name'\n",
    "        point = placemark.find('.//kml:Point/kml:coordinates', namespace)\n",
    "        if point is not None:\n",
    "            lon, lat, _ = point.text.split(',')\n",
    "            data.append([name, float(lat), float(lon)])\n",
    "\n",
    "    # Step 3: Create a DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"Name\", \"Latitude\", \"Longitude\"])\n",
    "\n",
    "    # Step 4: Create Folium map and add points\n",
    "    folium_map = folium.Map(location=[df[\"Latitude\"].mean(), df[\"Longitude\"].mean()], zoom_start=6)\n",
    "\n",
    "    # Add markers from the KMZ file\n",
    "    for _, row in df.iterrows():\n",
    "        folium.Marker(\n",
    "            location=(row['Latitude'], row['Longitude']),\n",
    "            popup=row['Name'],\n",
    "            icon=folium.Icon()\n",
    "        ).add_to(folium_map)\n",
    "\n",
    "    # Add the ArcGIS Feature Server layer\n",
    "    esri_feature_layer = folium.FeatureGroup(name='BNSF Railway')\n",
    "    esri_url = 'https://services3.arcgis.com/6rJKAjBRDRSfjCzV/arcgis/rest/services/BNSF_Railway/FeatureServer/0/query'\n",
    "    esri_params = {\n",
    "        'where': '1=1',\n",
    "        'outFields': '*',\n",
    "        'f': 'geojson'\n",
    "    }\n",
    "\n",
    "    def style_function(feature):\n",
    "        return {\n",
    "            'color': 'orange',\n",
    "            'weight': 2,\n",
    "            'fillOpacity': 0.6\n",
    "        }\n",
    "\n",
    "    response = requests.get(esri_url, params=esri_params)\n",
    "    geojson_data = response.json()\n",
    "\n",
    "    folium.GeoJson(\n",
    "        geojson_data,\n",
    "        name=\"BNSF Railway\",\n",
    "        style_function=style_function\n",
    "    ).add_to(esri_feature_layer)\n",
    "\n",
    "    esri_feature_layer.add_to(folium_map)\n",
    "\n",
    "    folium.LayerControl().add_to(folium_map)\n",
    "\n",
    "    return folium_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdfd9ac-22f3-4b0a-a6dc-1a95097d1d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_up_map(kmz_file_path):\n",
    "    # Step 1: Extract KMZ file\n",
    "    with zipfile.ZipFile(kmz_file_path, 'r') as kmz:\n",
    "        # Extract the KML file within the KMZ archive\n",
    "        kml_file_path = [name for name in kmz.namelist() if name.endswith('.kml')][0]\n",
    "        kml_content = kmz.read(kml_file_path)\n",
    "\n",
    "    # Step 2: Parse the KML file\n",
    "    namespace = {\"kml\": \"http://www.opengis.net/kml/2.2\"}\n",
    "    kml_root = ET.fromstring(kml_content)\n",
    "    document = kml_root.find('kml:Document', namespace)\n",
    "\n",
    "    placemarks = document.findall(\".//kml:Placemark\", namespace)\n",
    "\n",
    "    data = []\n",
    "    for placemark in placemarks:\n",
    "        name = placemark.find('kml:name', namespace).text if placemark.find('kml:name',\n",
    "                                                                            namespace) is not None else 'No Name'\n",
    "        point = placemark.find('.//kml:Point/kml:coordinates', namespace)\n",
    "        if point is not None:\n",
    "            lon, lat, _ = point.text.split(',')\n",
    "            data.append([name, float(lat), float(lon)])\n",
    "\n",
    "    # Step 3: Create a DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"Name\", \"Latitude\", \"Longitude\"])\n",
    "\n",
    "    # Step 4: Create Folium map and add points\n",
    "    folium_map = folium.Map(location=[df[\"Latitude\"].mean(), df[\"Longitude\"].mean()], zoom_start=6)\n",
    "\n",
    "    # Add markers from the KMZ file\n",
    "    for _, row in df.iterrows():\n",
    "        folium.Marker(\n",
    "            location=(row['Latitude'], row['Longitude']),\n",
    "            popup=row['Name'],\n",
    "            icon=folium.Icon()\n",
    "        ).add_to(folium_map)\n",
    "\n",
    "    # Add the ArcGIS Feature Server layer\n",
    "    esri_feature_layer = folium.FeatureGroup(name='Union Pacific Railway')\n",
    "    esri_url = 'https://services3.arcgis.com/6rJKAjBRDRSfjCzV/arcgis/rest/services/Union_Pacific_Railroad/FeatureServer/0/query'\n",
    "    esri_params = {\n",
    "        'where': '1=1',\n",
    "        'outFields': '*',\n",
    "        'f': 'geojson'\n",
    "    }\n",
    "\n",
    "    def style_function(feature):\n",
    "        return {\n",
    "            'color': 'orange',\n",
    "            'weight': 2,\n",
    "            'fillOpacity': 0.6\n",
    "        }\n",
    "\n",
    "    response = requests.get(esri_url, params=esri_params)\n",
    "    geojson_data = response.json()\n",
    "\n",
    "    folium.GeoJson(\n",
    "        geojson_data,\n",
    "        name=\"BNSF Railway\",\n",
    "        style_function=style_function\n",
    "    ).add_to(esri_feature_layer)\n",
    "\n",
    "    esri_feature_layer.add_to(folium_map)\n",
    "\n",
    "    folium.LayerControl().add_to(folium_map)\n",
    "\n",
    "    return folium_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d019db5c-5b85-4641-800b-eb9bfe9ee297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ns_map(kmz_file_path, add_offices=True):\n",
    "    # Step 1: Extract KMZ file\n",
    "    with zipfile.ZipFile(kmz_file_path, 'r') as kmz:\n",
    "        # Extract the KML file within the KMZ archive\n",
    "        kml_file_path = [name for name in kmz.namelist() if name.endswith('.kml')][0]\n",
    "        kml_content = kmz.read(kml_file_path)\n",
    "\n",
    "    # Step 2: Parse the KML file\n",
    "    namespace = {\"kml\": \"http://www.opengis.net/kml/2.2\"}\n",
    "    kml_root = ET.fromstring(kml_content)\n",
    "    document = kml_root.find('kml:Document', namespace)\n",
    "\n",
    "    placemarks = document.findall(\".//kml:Placemark\", namespace)\n",
    "\n",
    "    data = []\n",
    "    for placemark in placemarks:\n",
    "        name = placemark.find('kml:name', namespace).text if placemark.find('kml:name',\n",
    "                                                                            namespace) is not None else 'No Name'\n",
    "        point = placemark.find('.//kml:Point/kml:coordinates', namespace)\n",
    "        if point is not None:\n",
    "            lon, lat, _ = point.text.split(',')\n",
    "            data.append([name, float(lat), float(lon)])\n",
    "\n",
    "    # Step 3: Create a DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"Name\", \"Latitude\", \"Longitude\"])\n",
    "\n",
    "    # Step 4: Create Folium map and add points\n",
    "    folium_map = folium.Map(location=[df[\"Latitude\"].mean(), df[\"Longitude\"].mean()], zoom_start=6)\n",
    "\n",
    "    # Add markers from the KMZ file\n",
    "    for _, row in df.iterrows():\n",
    "        folium.Marker(\n",
    "            location=(row['Latitude'], row['Longitude']),\n",
    "            popup=row['Name'],\n",
    "            icon=folium.Icon()\n",
    "        ).add_to(folium_map)\n",
    "\n",
    "    # Add the NS Railway layer\n",
    "    esri_feature_layer = folium.FeatureGroup(name='Norfolk Southern Railway')\n",
    "    esri_url = 'https://services3.arcgis.com/6rJKAjBRDRSfjCzV/ArcGIS/rest/services/Norfolk_Southern_Railway/FeatureServer/0/query'\n",
    "    esri_params = {\n",
    "        'where': '1=1',\n",
    "        'outFields': '*',\n",
    "        'f': 'geojson'\n",
    "    }\n",
    "\n",
    "    def style_function(feature):\n",
    "        return {\n",
    "            'color': 'orange',\n",
    "            'weight': 2,\n",
    "            'fillOpacity': 0.6\n",
    "        }\n",
    "    \n",
    "    response = requests.get(esri_url, params=esri_params)\n",
    "    geojson_data = response.json()\n",
    "\n",
    "    folium.GeoJson(\n",
    "        geojson_data,\n",
    "        name=\"NS Railway\",\n",
    "        style_function=style_function\n",
    "    ).add_to(esri_feature_layer)\n",
    "\n",
    "    esri_feature_layer.add_to(folium_map)\n",
    "\n",
    "    # Conditionally add the office layer when add_offices is True\n",
    "    if add_offices:\n",
    "        office_layer_url = 'https://services1.arcgis.com/q8sarOko6mCDwiGm/arcgis/rest/services/Michael_Baker_International_Offices_Sep_22/FeatureServer/0/query'\n",
    "        office_layer_params = {\n",
    "            'where': '1=1',\n",
    "            'outFields': '*',\n",
    "            'f': 'geojson'\n",
    "        }\n",
    "\n",
    "        office_response = requests.get(office_layer_url, params=office_layer_params)\n",
    "        office_geojson_data = office_response.json()\n",
    "\n",
    "        # Add the office layer markers to the map\n",
    "        for feature in office_geojson_data['features']:\n",
    "            try:\n",
    "                # Extract coordinates and properties from each feature\n",
    "                coords = feature[\"geometry\"][\"coordinates\"]\n",
    "                properties = feature[\"properties\"]\n",
    "\n",
    "                # Create black building markers\n",
    "                folium.Marker(\n",
    "                    location=[coords[1], coords[0]],  # GeoJSON coordinates are [lon, lat]\n",
    "                    popup=properties.get('name', 'Office'),\n",
    "                    icon=folium.Icon(icon=\"building\", prefix=\"fa\", color=\"black\")\n",
    "                ).add_to(folium_map)\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "    folium.LayerControl().add_to(folium_map)\n",
    "\n",
    "    return folium_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21a4ac4a-65fe-4c45-9330-fce855bd407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "kmz_file_path = r\"C:\\Users\\dane.parks\\OneDrive - Michael Baker International\\Project Location maps\\MBI_Rail_Projects_no_prior_firms.kmz\"\n",
    "map = generate_ns_map(kmz_file_path)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map.save(r'C:\\Users\\dane.parks\\OneDrive - Michael Baker International\\Project Location maps\\ns_rail_projects_map.html')\n",
    "\n",
    "# To display in Jupyter Notebook\n",
    "# from IPython.display import IFrame\n",
    "# IFrame('rail_projects_map.html', width='100%', height='600px')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f861bb10-82a9-47e3-afa8-7c35419cf774",
   "metadata": {},
   "source": [
    "## Working Examples Are Above, These Are Experimental Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "320f396a-c842-482e-b762-efe45541774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "railway_dict = {\n",
    "    'NS': [\n",
    "            'Norfolk Southern Railway',  # Name\n",
    "            'https://services3.arcgis.com/6rJKAjBRDRSfjCzV/ArcGIS/rest/services/Norfolk_Southern_Railway/FeatureServer/0/query',  # ESRI URL Name\n",
    "            'black'                      # Map Color\n",
    "            ],\n",
    "    'CSX': [\n",
    "            'CSX Railway',               # Name\n",
    "            'https://services.arcgis.com/xOi1kZaI0eWDREZv/arcgis/rest/services/NTAD_North_American_Rail_Network_Lines_CSXT/FeatureServer/0/query',  # ESRI URL Name\n",
    "            'blue'                       # Map Color\n",
    "        ],\n",
    "    'BNSF': [\n",
    "            'BNSF Railway',               # Name\n",
    "            'https://services3.arcgis.com/6rJKAjBRDRSfjCzV/ArcGIS/rest/services/BNSF_Railway/FeatureServer/0/query',  # ESRI URL Name\n",
    "            'orange'                      # Map Color\n",
    "        ], \n",
    "    'UP': [\n",
    "            'Union Pacific Railway',      # Name\n",
    "            'https://services3.arcgis.com/6rJKAjBRDRSfjCzV/ArcGIS/rest/services/UP/FeatureServer/0/query',  # ESRI URL Name\n",
    "            'yellow'                      # Map Color\n",
    "        ], \n",
    "    'CN': [\n",
    "            'Canadian National Railway',  # Name\n",
    "            'https://services3.arcgis.com/6rJKAjBRDRSfjCzV/ArcGIS/rest/services/CN/FeatureServer/0/query',  # ESRI URL Name\n",
    "            'red'                         # Map Color\n",
    "        ], \n",
    "    'CPKC': [\n",
    "            'Canadian Pacific Kansas City',  # Name\n",
    "            'https://services3.arcgis.com/6rJKAjBRDRSfjCzV/ArcGIS/rest/services/CPKC/FeatureServer/0/query',  # ESRI URL Name\n",
    "            'gold'                            # Map Color\n",
    "        ], \n",
    "    'Baker Offices': [\n",
    "            'Michael Baker International',\n",
    "            'https://services1.arcgis.com/q8sarOko6mCDwiGm/arcgis/rest/services/Michael_Baker_International_Offices_Sep_22/FeatureServer/0'\n",
    "            'black'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def add_feature_layer(railway, m):\n",
    "    \n",
    "    rail_feature_layer = folium.FeatureGroup(name=railway_dict[railway][0], show=True)\n",
    "    esri_url = name=railway_dict[railway][1]\n",
    "    esri_params = {\n",
    "        'where': '1=1',\n",
    "        'outFields': '*',\n",
    "        'f': 'geojson'\n",
    "    }\n",
    "\n",
    "    def style_function(feature):\n",
    "        return {\n",
    "            'color': railway_dict[railway][2],\n",
    "            'weight': 2,\n",
    "            'fillOpacity': 0.6\n",
    "        }\n",
    "\n",
    "    response = requests.get(esri_url, params=esri_params)\n",
    "    geojson_data = response.json()\n",
    "\n",
    "    folium.GeoJson(\n",
    "        geojson_data,\n",
    "        name=railway_dict[railway][0],\n",
    "        style_function=style_function\n",
    "    ).add_to(rail_feature_layer)\n",
    "    rail_feature_layer.add_to(m)\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3125b9-4b5a-4520-aa1e-7442cceacd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_detailed_map(kmz_file_path):\n",
    "    # Step 1: Extract KMZ file\n",
    "    with zipfile.ZipFile(kmz_file_path, 'r') as kmz:\n",
    "        # Extract the KML file within the KMZ archive\n",
    "        kml_file_path = [name for name in kmz.namelist() if name.endswith('.kml')][0]\n",
    "        kml_content = kmz.read(kml_file_path)\n",
    "\n",
    "    # Step 2: Parse the KML file\n",
    "    namespace = {\"kml\": \"http://www.opengis.net/kml/2.2\"}\n",
    "    kml_root = ET.fromstring(kml_content)\n",
    "    document = kml_root.find('kml:Document', namespace)\n",
    "\n",
    "    # Step 3: Map folders to placemarks\n",
    "    def get_placemarks_with_folders(element, folder_name=None):\n",
    "        \"\"\"\n",
    "        Recursively traverse the tree to associate placemarks with their folder names.\n",
    "        \"\"\"\n",
    "        placemark_data = []\n",
    "\n",
    "        # Check if the element is a Folder and update the folder name\n",
    "        current_folder_name = folder_name\n",
    "        if element.tag == f\"{{{namespace['kml']}}}Folder\":\n",
    "            folder_name_elem = element.find('kml:name', namespace)\n",
    "            current_folder_name = folder_name_elem.text if folder_name_elem is not None else \"No Folder\"\n",
    "\n",
    "        # Process Placemark elements inside the current Folder\n",
    "        for placemark in element.findall('kml:Placemark', namespace):\n",
    "            placemark_data.append((current_folder_name, placemark))\n",
    "\n",
    "        # Traverse deeper into the tree for nested elements\n",
    "        for child in element:\n",
    "            placemark_data.extend(get_placemarks_with_folders(child, current_folder_name))\n",
    "\n",
    "        return placemark_data\n",
    "\n",
    "    # Get placemarks with folder data\n",
    "    placemarks_with_folders = get_placemarks_with_folders(document)\n",
    "\n",
    "    # Step 4: Extract placemark data (Name, Folder, and Coordinates)\n",
    "    data = []\n",
    "    folder_groups = {}\n",
    "    for folder_name, placemark in placemarks_with_folders:\n",
    "        name = placemark.find('kml:name', namespace).text if placemark.find('kml:name',\n",
    "                                                                            namespace) is not None else 'No Name'\n",
    "        point = placemark.find('.//kml:Point/kml:coordinates', namespace)\n",
    "        if point is not None:\n",
    "            lon, lat, _ = point.text.split(',')\n",
    "            data.append([folder_name, name, float(lat), float(lon)])\n",
    "\n",
    "    # Step 5: Create a Folium map\n",
    "    if len(data) == 0:\n",
    "        raise ValueError(\"No placemarks with valid coordinates found in the KMZ file.\")\n",
    "    df = pd.DataFrame(data, columns=[\"Folder\", \"Name\", \"Latitude\", \"Longitude\"])\n",
    "    folium_map = folium.Map(location=[df[\"Latitude\"].mean(), df[\"Longitude\"].mean()], zoom_start=6)\n",
    "\n",
    "    # Step 6: Add markers by folder\n",
    "    for folder_name in df[\"Folder\"].unique():\n",
    "        # Create a feature group for the folder\n",
    "        feature_group = folium.FeatureGroup(name=folder_name, show=True)\n",
    "        folder_df = df[df[\"Folder\"] == folder_name]\n",
    "\n",
    "        # Add all placemarks from this folder to the feature group\n",
    "        for _, row in folder_df.iterrows():\n",
    "            folium.Marker(\n",
    "                location=(row[\"Latitude\"], row[\"Longitude\"]),\n",
    "                popup=f\"{row['Name']}\",\n",
    "                icon=folium.Icon()\n",
    "            ).add_to(feature_group)\n",
    "\n",
    "        # Add the feature group to the map\n",
    "        feature_group.add_to(folium_map)\n",
    "\n",
    "    add_feature_layer('NS', folium_map)\n",
    "    add_feature_layer('CSX', folium_map)  # //TODO - Fix\n",
    "    add_feature_layer('BNSF', folium_map)\n",
    "    add_feature_layer('UP', folium_map)   # //TODO - Fix\n",
    "    add_feature_layer('CN', folium_map)   # //TODO - Fix? Might be okay\n",
    "    add_feature_layer('CPKC', folium_map) # //TODO - Fix\n",
    "\n",
    "    # Step 8: Add a LayerControl to toggle folders\n",
    "    folium.LayerControl().add_to(folium_map)\n",
    "\n",
    "    return folium_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8463dde-758c-4008-a372-3e1b05a1a25b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zipfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m m \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_detailed_map\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC:\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mUsers\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mdane.parks\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mOneDrive - Michael Baker International\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mProject Location maps\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mMBI_Rail_Projects.kmz\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[2], line 3\u001B[0m, in \u001B[0;36mgenerate_detailed_map\u001B[1;34m(kmz_file_path)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mgenerate_detailed_map\u001B[39m(kmz_file_path):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m# Step 1: Extract KMZ file\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mzipfile\u001B[49m\u001B[38;5;241m.\u001B[39mZipFile(kmz_file_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m kmz:\n\u001B[0;32m      4\u001B[0m         \u001B[38;5;66;03m# Extract the KML file within the KMZ archive\u001B[39;00m\n\u001B[0;32m      5\u001B[0m         kml_file_path \u001B[38;5;241m=\u001B[39m [name \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m kmz\u001B[38;5;241m.\u001B[39mnamelist() \u001B[38;5;28;01mif\u001B[39;00m name\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.kml\u001B[39m\u001B[38;5;124m'\u001B[39m)][\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m      6\u001B[0m         kml_content \u001B[38;5;241m=\u001B[39m kmz\u001B[38;5;241m.\u001B[39mread(kml_file_path)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'zipfile' is not defined"
     ]
    }
   ],
   "source": [
    "m = generate_detailed_map(r\"C:\\Users\\dane.parks\\OneDrive - Michael Baker International\\Project Location maps\\MBI_Rail_Projects.kmz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "757f29a9-d2aa-4146-8cdf-4f418f23c18d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mm\u001B[49m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8194ced-7795-4389-8de8-fa9538d8a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce276e4-97f6-441a-a050-901d0123c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_features(esri_url, params):\n",
    "    all_features = []\n",
    "    params[\"resultOffset\"] = 0  # Start offset\n",
    "    params[\"resultRecordCount\"] = 2000  # Max number of features per page (adjust based on server limits)\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(esri_url, params=params)\n",
    "\n",
    "        # Check if the request succeeds\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch data: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        # Append features received in this batch\n",
    "        if \"features\" in data:\n",
    "            all_features.extend(data[\"features\"])\n",
    "\n",
    "            # Check if there are more features to fetch\n",
    "            if len(data[\"features\"]) < params[\"resultRecordCount\"]:\n",
    "                break  # No more features left\n",
    "            else:\n",
    "                # Increment the offset to fetch next batch\n",
    "                params[\"resultOffset\"] += params[\"resultRecordCount\"]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Wrap all features into a GeoJSON-like structure\n",
    "    return {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": all_features,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f09c24a-f61a-4752-bd6d-4162b8414525",
   "metadata": {},
   "source": [
    "# Project breakdown by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5368a92-e9d1-42d8-ac18-e2355afbfd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmz_file_path = r\"C:\\Users\\dane.parks\\OneDrive - Michael Baker International\\Project Location maps\\MBI_Rail_Projects_no_prior_firms.kmz\"\n",
    "\n",
    "# Step 1: Extract KMZ file\n",
    "with zipfile.ZipFile(kmz_file_path, 'r') as kmz:\n",
    "    # Extract the KML file within the KMZ archive\n",
    "    kml_file_path = [name for name in kmz.namelist() if name.endswith('.kml')][0]\n",
    "    kml_content = kmz.read(kml_file_path)\n",
    "\n",
    "# Step 2: Parse the KML file\n",
    "namespace = {\"kml\": \"http://www.opengis.net/kml/2.2\"}\n",
    "kml_root = ET.fromstring(kml_content)\n",
    "document = kml_root.find('kml:Document', namespace)\n",
    "\n",
    "placemarks = document.findall(\".//kml:Placemark\", namespace)\n",
    "\n",
    "data = []\n",
    "for placemark in placemarks:\n",
    "    name = placemark.find('kml:name', namespace).text if placemark.find('kml:name',\n",
    "                                                                        namespace) is not None else 'No Name'\n",
    "    point = placemark.find('.//kml:Point/kml:coordinates', namespace)\n",
    "    if point is not None:\n",
    "        lon, lat, _ = point.text.split(',')\n",
    "        data.append([name, float(lat), float(lon)])\n",
    "\n",
    "# Step 3: Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Name\", \"Latitude\", \"Longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6463484e-023a-4b89-ba69-b67d224a8898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b172850-5beb-44ca-a894-376d82e2f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load U.S. states shapefile/GeoJSON\n",
    "# Change the file path below to the location of your shapefile or GeoJSON\n",
    "states = gpd.read_file(r\"C:\\Users\\dane.parks\\PycharmProjects\\civilpy\\src\\civilpy\\data\\gis_boundaries\\tl_2024_us_state.shp\")\n",
    "\n",
    "# Ensure the coordinate reference system (CRS) is properly set\n",
    "states = states.to_crs(\"EPSG:4326\")  # WGS84, to match with GPS coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e43133-ae41-4d46-a680-35209d687263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "# Create geometry column with shapely Points\n",
    "geometry = [Point(xy) for xy in zip(df['Longitude'], df['Latitude'])]\n",
    "\n",
    "# Convert to a GeoDataFrame\n",
    "geo_points = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "# Set the CRS to WGS84 (EPSG:4326) to match the states GeoDataFrame\n",
    "geo_points.crs = \"EPSG:4326\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d9b94-8d87-4a58-a760-fc2c2d8b75a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2252111b-a22e-481e-9723-e12206c49933",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c6005-0809-498a-9d3f-25ae5c97f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform spatial join: matches each point to the state it belongs to\n",
    "points_with_states = gpd.sjoin(geo_points, states, how=\"left\", predicate=\"intersects\")\n",
    "\n",
    "# Group by state and count the points\n",
    "points_per_state = points_with_states.groupby('NAME')['Name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0dda2c-ca4c-4ae6-a0cf-4ee055621a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_per_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0dc54-dfb1-44d9-ae1b-4776b24c6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \n",
    "    \"Connecticut\", \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \n",
    "    \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \n",
    "    \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \n",
    "    \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \n",
    "    \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \n",
    "    \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \n",
    "    \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \n",
    "    \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \n",
    "    \"West Virginia\", \"Wisconsin\", \"Wyoming\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ca43b-3e68-4793-836f-4afb28953dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_states = points_per_state.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6703b9bc-77a9-4016-8fd5-454bfa40db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_states = set(us_states) - set(result_states)\n",
    "\n",
    "print(\"Missing states:\", missing_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d0bc74-c0b6-4b61-8ac8-8a329957ea96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
